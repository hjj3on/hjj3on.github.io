<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head>
    <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8">
    <link rel="stylesheet" href="jemdoc.css" type="text/css">
    <title>Hong Jun Jeon: Research</title>
    </head>
    <body>
    <table summary="Table for page layout." id="tlayout">
    <tbody><tr valign="top">
    <td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="publications.html">Publications</a></div>
    </td>
    <td id="layout-content">
    <div id="toptitle">
    <h1>Hong Jun Jeon: Research</h1>
    </div>
    <h2>Developing Coherent Frameworks for Machine Learning</h2>
    <p>
        My research focuses on developing coherent frameworks for reasoning about the various puzzling phenomena of modern machine learning.
        In recent years I have explored how we can leverage the tools of information theory and Bayesian statistics to arrive at plaussible explanations (rooted in rigorous mathematics) for the behavior of deep learning models.
        The hope is that this work can help to demystify the "alchemy" of machine learning and establish truths from which we can coherently reason.  The long-term vision is to leverage these novel insights to develop new algorithmic ideas across a wide range of machine learning problems.
    </p>
    <h2>Recommended reading</h2>
    <p>Papers listed below introduce facets of my research.
    </p>
    <h3>Information-theoretic foundations</h3>
    <p>Information theory offers elegant tools for analysis of machine learning.  These tools accomodate great generality, handling models that are parametric or nonparametric and that involve discrete or continuous variables that are noisy or noiseless, as well as problems of sequential decision and learning.
        Foundations for analysis of error and sample complexity can be found in this paper, along with a result that illustrates how these tools can generate novel insights (stay tuned for an updated monograph encompassing these and other results):
    </p>
    <ul>
    <li><p><a href="https://arxiv.org/abs/2203.00246" target="“blank”">An Information-Theoretic Framework for Supervised Learning</a>
    </p>
    </li>
    </ul>
    <p>Information theory can inform the design and analysis of continual learning:
    </p>
    <ul>
    <li><p><a href="https://arxiv.org/abs/2307.04345" target="“blank”">Continual Learning as Computationally Constrained Reinforcement Learning</a>
    </p>
    </li>
    </ul>
    <h3>Information theory for LLMs</h3>
    <p>
        The astonishing capabilities of large language models (LLMs) have been accompanied by a host of puzzling phenomena.  The following papers analyze two of these phenomena (in-context learning and neural scaling laws) and offer elegant results rooted in information theory:
    </p>
    <ul>
    <li><p><a href="https://arxiv.org/abs/2401.15530" target="“blank”">An Information-Theoretic Analysis of In-context Learning</a>
    </p>
    </li>
    <li><p><a href="https://arxiv.org/abs/2212.01365" target="“blank”">An Information-Theoretic Analysis of Compute-Optimal Neural Scaling Laws</a>
    </p>
    </li>
    </ul>
    <p>
    </p>
    <h3>Learning from human feedback</h3>
    <p>
        Throughout my research career I have been interested in the problem of learning from human feedback.  This has become an increasingly
        important step in the deployment of machine learning systems which are aligned with human values.  Learning from human interactions is a challenging problem and involves a plethora of modalities i.e. demonstrations, preferences, natural language, etc.  This paper offers a unifying
        Bayesian framework for learning from all such modalities.
    </p>
    <ul>
    <li><p><a href="https://proceedings.neurips.cc/paper/2020/hash/2f10c1578a0706e06b6d7db6f0b4a6af-Abstract.html" target="“blank”">Reward-rational (implicit) choice: A unifying formalism for reward learning</a>
    </p>
    </li>
    </ul>
    <p>
        Learning from human feedback is also expensive and time-prohibitive.  As a result, it is important to develop algorithms which extract the most information from the human interactions.
        This paper offers a novel algorithmic approach to implicitly learning the skills and correlation between human crowd workers:
    </p>
    <ul>
    <li><p><a href="https://arxiv.org/abs/2401.13239" target="“blank”">Adaptive Crowdsourcing Via Self-Supervised Learning
    </a>
    </p>
    </li>
    <div id="footer">
    <div id="footer-text">
    Page generated 2024-03-02 12:28:21 PST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
    </div>
    </div>
    </td>
    </tr>
    </tbody></table>
    
    
    </body></html>