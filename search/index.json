[{"content":"Authors  Hong Jun Jeon\nDepartment of Computer Science,\nStanford University\n Yifan Zhu\nDepartment of Electrical Engineering,\nStanford University\n Benjamin Van Roy\nDepartment of Electrical Engineering,\nDepartment of Management Sciences and Engineering,\nStanford University\nAbstract  Each year, deep learning demonstrates new and improved empirical results with deeper and wider neural networks. Meanwhile, with existing theoretical frameworks, it is difficult to analyze networks deeper than two layers without resorting to counting parameters or encountering sample complexity bounds that are exponential in depth. Perhaps it may be fruitful to try to analyze modern machine learning under a different lens. In this paper, we propose a novel information-theoretic framework with its own notions of regret and sample complexity for analyzing the data requirements of machine learning. With our framework, we first work through some classical examples such as scalar estimation and linear regression to build intuition and introduce general techniques. Then, we use the framework to study the sample complexity of learning from data generated by deep neural networks with ReLU activation units. For a particular prior distribution on weights, we establish sample complexity bounds that are simultaneously width independent and linear in depth. This prior distribution gives rise to high-dimensional latent representations that, with high probability, admit reasonably accurate low-dimensional approximations. We conclude by corroborating our theoretical results with experimental analysis of random single-hidden-layer neural networks. Reference  Arxiv Link Submission  In submission to JMLR ","date":"2023-03-24T00:00:00Z","image":"https://hjjeon.github.io/p/info-theory-supervised-learning/info_theory.svg","permalink":"https://hjjeon.github.io/p/info-theory-supervised-learning/","title":"An Information Theoretic Framework for Supervised Learning"},{"content":"Authors  Hong Jun Jeon\nDepartment of Computer Science,\nStanford University\n Benjamin Van Roy\nDepartment of Electrical Engineering,\nDepartment of Management Sciences and Engineering,\nStanford University\nAbstract  Each year, deep learning demonstrate new and improved empirical results with deeper and wider neural networks. Meanwhile, with existing theoretical frameworks, it is difficult to analyze networks deeper than two layers without resorting to counting parameters or encountering sample complexity bounds that are exponential in depth. Perhaps it may be fruitful to try to analyze modern machine learning under a different lens. In this paper, we propose a novel information-theoretic framework with its own notions of regret and sample complexity for analyzing the data requirements of machine learning. We use this framework to study the sample complexity of learning from data generated by deep ReLU neural networks and deep networks that are infinitely wide but have a bounded sum of weights. We establish that the sample complexity of learning under these data generating processes is at most linear and quadratic, respectively, in network depth. Reference  Neurips Link Submission  Accepted at Neurips 2022 ","date":"2022-05-22T00:00:00Z","image":"https://hjjeon.github.io/p/info-theory-deep-learning/NN.svg","permalink":"https://hjjeon.github.io/p/info-theory-deep-learning/","title":"An Information Theoretic Framework for Deep Learning"},{"content":"Authors  Hong Jun Jeon\nDepartment of Computer Science,\nStanford University\n Smitha Milli\nDepartment of Computer Science,\nUC Berkeley\n Anca D. Dragan\nDepartment of Computer Science,\nUC Berkeley\nAbstract  It is often difficult to hand-specify what the correct reward function is for a task, so researchers have instead aimed to learn reward functions from human behavior or feedback. The types of behavior interpreted as evidence of the reward function have expanded greatly in recent years. We've gone from demonstrations, to comparisons, to reading into the information leaked when the human is pushing the robot away or turning it off. And surely, there is more to come. How will a robot make sense of all these diverse types of behavior? Our key observation is that different types of behavior can be interpreted in a single unifying formalism - as a reward-rational choice that the human is making, often implicitly. We use this formalism to survey prior work through a unifying lens, and discuss its potential use as a recipe for interpreting new sources of information that are yet to be uncovered. Reference  Neurips Link Submission  Published at Neurips 2020 ","date":"2020-12-11T00:00:00Z","image":"https://hjjeon.github.io/p/rric/RRIC.svg","permalink":"https://hjjeon.github.io/p/rric/","title":"Reward Rational (Implicit) Choice: a unifying formalism for reward learning"},{"content":"Authors  Hong Jun Jeon\nDepartment of Computer Science,\nStanford University\n Dylan P. Losey\nDepartment of Mechanical Engineering,\nVirginia Tech\n Dorsa Sadigh\nDepartment of Computer Science,\nDepartment of Electrical Engineering,\nStanford University\nAbstract  Assistive robots enable people with disabilities to conduct everyday tasks on their own. However, these tasks can be complex, containing both coarse reaching motions and fine-grained manipulation. For example, when eating, not only does one need to move to the correct food item, but they must also precisely manipulate the food in different ways (e.g., cutting, stabbing, scooping). Shared autonomy methods make robot teleoperation safer and more precise by arbitrating user inputs with robot controls. However, these works have focused mainly on the high-level task of reaching a goal from a discrete set, while largely ignoring manipulation of objects at that goal. Meanwhile, dimensionality reduction techniques for teleoperation map useful high-dimensional robot actions into an intuitive low-dimensional controller, but it is unclear if these methods can achieve the requisite precision for tasks like eating. Our insight is that---by combining intuitive embeddings from learned latent actions with robotic assistance from shared autonomy---we can enable precise assistive manipulation. In this work, we adopt learned latent actions for shared autonomy by proposing a new model structure that changes the meaning of the human's input based on the robot's confidence of the goal. We show convergence bounds on the robot's distance to the most likely goal, and develop a training procedure to learn a controller that is able to move between goals even in the presence of shared autonomy. We evaluate our method in simulations and an eating user study. Reference  Arxiv Link Video  Youtube Link Award  RSS 2020 Best Student Paper Finalist ","date":"2020-05-11T00:00:00Z","image":"https://hjjeon.github.io/p/sall/SALL.svg","permalink":"https://hjjeon.github.io/p/sall/","title":"Shared Autonomy with Learned Latent Actions"},{"content":"Authors  Hong Jun Jeon\nDepartment of Computer Science,\nStanford University\n Anca D. Dragan\nDepartment of Computer Science,\nUC Berkeley\nAbstract  When robot manipulators decide how to reach for an object, hand it over, or obey some task constraint, they implicitly assume a Euclidean distance metric in their configuration space. Their notion of what makes a configuration closer or further is dictated by this assumption. But different distance metrics will lead to different solutions. What is efficient under a Euclidean metric might not necessarily look the most efficient or natural to a person observing the robot. In this paper, we analyze the effect of the metric on robot behavior, examining both Euclidean, as well as non-Euclidean metrics -- metrics that make certain joints cheaper, or that correlate different joints. Our user data suggests that tasks on a 3DOF arm and the Jaco 7DOF arm can typically be grouped into ones where a Euclidean metric works well, and tasks where that is no longer the case: there, surprisingly, penalizing elbow motion (and sometimes correlating the shoulder and wrist) leads to solutions that are more aligned with what users prefer. Reference  Arxiv Link Award  IROS 2018 Best Student Paper Finalist ","date":"2018-08-12T00:00:00Z","image":"https://hjjeon.github.io/p/csm/config.svg","permalink":"https://hjjeon.github.io/p/csm/","title":"Configuration Space Metrics"}]