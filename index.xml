<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hong Jun Jeon</title>
        <link>https://hjjeon.github.io/</link>
        <description>Recent content on Hong Jun Jeon</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Fri, 24 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://hjjeon.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>An Information Theoretic Framework for Supervised Learning</title>
        <link>https://hjjeon.github.io/p/info-theory-supervised-learning/</link>
        <pubDate>Fri, 24 Mar 2023 00:00:00 +0000</pubDate>
        
        <guid>https://hjjeon.github.io/p/info-theory-supervised-learning/</guid>
        <description>&lt;img src="https://hjjeon.github.io/p/info-theory-supervised-learning/info_theory.svg" alt="Featured image of post An Information Theoretic Framework for Supervised Learning" /&gt;&lt;h3 id=&#34;authors&#34;&gt;Authors&lt;/h3&gt;
&lt;p&gt;
    Hong Jun Jeon&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
    Yifan Zhu&lt;br&gt;
    Department of Electrical Engineering,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
    Benjamin Van Roy&lt;br&gt;
    Department of Electrical Engineering,&lt;br&gt;
    Department of Management Sciences and Engineering,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;
    Each year, deep learning demonstrates new and improved empirical results with deeper
    and wider neural networks. Meanwhile, with existing theoretical frameworks, it is difficult
    to analyze networks deeper than two layers without resorting to counting parameters or
    encountering sample complexity bounds that are exponential in depth. Perhaps it may be
    fruitful to try to analyze modern machine learning under a different lens. In this paper,
    we propose a novel information-theoretic framework with its own notions of regret and
    sample complexity for analyzing the data requirements of machine learning. With our
    framework, we first work through some classical examples such as scalar estimation and
    linear regression to build intuition and introduce general techniques. Then, we use the
    framework to study the sample complexity of learning from data generated by deep neural
    networks with ReLU activation units. For a particular prior distribution on weights, we
    establish sample complexity bounds that are simultaneously width independent and linear
    in depth. This prior distribution gives rise to high-dimensional latent representations that,
    with high probability, admit reasonably accurate low-dimensional approximations. We
    conclude by corroborating our theoretical results with experimental analysis of random
    single-hidden-layer neural networks.
&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;p&gt;
    &lt;a href=&#34;https://arxiv.org/abs/2203.00246&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Arxiv Link&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;submission&#34;&gt;Submission&lt;/h3&gt;
&lt;p&gt;
    In submission to &lt;a href=&#34;https://www.jmlr.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;JMLR&lt;/a&gt;
&lt;/p&gt;</description>
        </item>
        <item>
        <title>An Information Theoretic Framework for Deep Learning</title>
        <link>https://hjjeon.github.io/p/info-theory-deep-learning/</link>
        <pubDate>Sun, 22 May 2022 00:00:00 +0000</pubDate>
        
        <guid>https://hjjeon.github.io/p/info-theory-deep-learning/</guid>
        <description>&lt;img src="https://hjjeon.github.io/p/info-theory-deep-learning/NN.svg" alt="Featured image of post An Information Theoretic Framework for Deep Learning" /&gt;&lt;h3 id=&#34;authors&#34;&gt;Authors&lt;/h3&gt;
&lt;p&gt;
    Hong Jun Jeon&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
    Benjamin Van Roy&lt;br&gt;
    Department of Electrical Engineering,&lt;br&gt;
    Department of Management Sciences and Engineering,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;
    Each year, deep learning demonstrate new and improved empirical results with
    deeper and wider neural networks. Meanwhile, with existing theoretical frameworks, it is difficult to analyze networks deeper than two layers without resorting
    to counting parameters or encountering sample complexity bounds that are exponential in depth. Perhaps it may be fruitful to try to analyze modern machine learning under a different lens. In this paper, we propose a novel information-theoretic
    framework with its own notions of regret and sample complexity for analyzing the
    data requirements of machine learning. We use this framework to study the sample complexity of learning from data generated by deep ReLU neural networks
    and deep networks that are infinitely wide but have a bounded sum of weights.
    We establish that the sample complexity of learning under these data generating
    processes is at most linear and quadratic, respectively, in network depth.
&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;p&gt;
    &lt;a href=&#34;https://papers.nips.cc/paper_files/paper/2022/hash/15cc8e4a46565dab0c1a1220884bd503-Abstract-Conference.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Neurips Link&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;submission&#34;&gt;Submission&lt;/h3&gt;
&lt;p&gt;
    Accepted at Neurips 2022
&lt;/p&gt;</description>
        </item>
        <item>
        <title>Reward Rational (Implicit) Choice: a unifying formalism for reward learning</title>
        <link>https://hjjeon.github.io/p/rric/</link>
        <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
        
        <guid>https://hjjeon.github.io/p/rric/</guid>
        <description>&lt;img src="https://hjjeon.github.io/p/rric/RRIC.svg" alt="Featured image of post Reward Rational (Implicit) Choice: a unifying formalism for reward learning" /&gt;&lt;h3 id=&#34;authors&#34;&gt;Authors&lt;/h3&gt;
&lt;p&gt;
    Hong Jun Jeon&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
    Smitha Milli&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    UC Berkeley&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
    Anca D. Dragan&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    UC Berkeley&lt;br&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;
    It is often difficult to hand-specify what the correct reward function is for a task, so researchers have instead aimed to learn reward functions from human behavior or feedback. The types of behavior interpreted as evidence of the reward function have expanded greatly in recent years. We&#39;ve gone from demonstrations, to comparisons, to reading into the information leaked when the human is pushing the robot away or turning it off. And surely, there is more to come. How will a robot make sense of all these diverse types of behavior? Our key observation is that different types of behavior can be interpreted in a single unifying formalism - as a reward-rational choice that the human is making, often implicitly. We use this formalism to survey prior work through a unifying lens, and discuss its potential use as a recipe for interpreting new sources of information that are yet to be uncovered.
&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;p&gt;
    &lt;a href=&#34;https://proceedings.neurips.cc/paper/2020/hash/2f10c1578a0706e06b6d7db6f0b4a6af-Abstract.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Neurips Link&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;submission&#34;&gt;Submission&lt;/h3&gt;
&lt;p&gt;
    Published at Neurips 2020
&lt;/p&gt;</description>
        </item>
        <item>
        <title>Shared Autonomy with Learned Latent Actions</title>
        <link>https://hjjeon.github.io/p/sall/</link>
        <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
        
        <guid>https://hjjeon.github.io/p/sall/</guid>
        <description>&lt;img src="https://hjjeon.github.io/p/sall/SALL.svg" alt="Featured image of post Shared Autonomy with Learned Latent Actions" /&gt;&lt;h3 id=&#34;authors&#34;&gt;Authors&lt;/h3&gt;
&lt;p&gt;
    Hong Jun Jeon&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
    Dylan P. Losey&lt;br&gt;
    Department of Mechanical Engineering,&lt;br&gt;
    Virginia Tech&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
    Dorsa Sadigh&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    Department of Electrical Engineering,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;
    Assistive robots enable people with disabilities to conduct everyday tasks on their own. However, these tasks can be complex, containing both coarse reaching motions and fine-grained manipulation. For example, when eating, not only does one need to move to the correct food item, but they must also precisely manipulate the food in different ways (e.g., cutting, stabbing, scooping). Shared autonomy methods make robot teleoperation safer and more precise by arbitrating user inputs with robot controls. However, these works have focused mainly on the high-level task of reaching a goal from a discrete set, while largely ignoring manipulation of objects at that goal. Meanwhile, dimensionality reduction techniques for teleoperation map useful high-dimensional robot actions into an intuitive low-dimensional controller, but it is unclear if these methods can achieve the requisite precision for tasks like eating. Our insight is that---by combining intuitive embeddings from learned latent actions with robotic assistance from shared autonomy---we can enable precise assistive manipulation. In this work, we adopt learned latent actions for shared autonomy by proposing a new model structure that changes the meaning of the human&#39;s input based on the robot&#39;s confidence of the goal. We show convergence bounds on the robot&#39;s distance to the most likely goal, and develop a training procedure to learn a controller that is able to move between goals even in the presence of shared autonomy. We evaluate our method in simulations and an eating user study.
&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;p&gt;
    &lt;a href=&#34;https://arxiv.org/abs/2005.03210&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Arxiv Link&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;
&lt;p&gt;
    &lt;a href=&#34;https://www.youtube.com/watch?v=7BouKojzVyk&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Youtube Link&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;award&#34;&gt;Award&lt;/h3&gt;
&lt;p&gt;
    &lt;a href=&#34;https://roboticsconference.org/2020/program/awards/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; RSS 2020 Best Student Paper Finalist&lt;/a&gt;
&lt;/p&gt;</description>
        </item>
        <item>
        <title>Configuration Space Metrics</title>
        <link>https://hjjeon.github.io/p/csm/</link>
        <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
        
        <guid>https://hjjeon.github.io/p/csm/</guid>
        <description>&lt;img src="https://hjjeon.github.io/p/csm/config.svg" alt="Featured image of post Configuration Space Metrics" /&gt;&lt;h3 id=&#34;authors&#34;&gt;Authors&lt;/h3&gt;
&lt;p&gt;
    Hong Jun Jeon&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    Stanford University&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
    Anca D. Dragan&lt;br&gt;
    Department of Computer Science,&lt;br&gt;
    UC Berkeley&lt;br&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;
    When robot manipulators decide how to reach for an object, hand it over, or obey some task constraint, they implicitly assume a Euclidean distance metric in their configuration space. Their notion of what makes a configuration closer or further is dictated by this assumption. But different distance metrics will lead to different solutions. What is efficient under a Euclidean metric might not necessarily look the most efficient or natural to a person observing the robot. In this paper, we analyze the effect of the metric on robot behavior, examining both Euclidean, as well as non-Euclidean metrics -- metrics that make certain joints cheaper, or that correlate different joints. Our user data suggests that tasks on a 3DOF arm and the Jaco 7DOF arm can typically be grouped into ones where a Euclidean metric works well, and tasks where that is no longer the case: there, surprisingly, penalizing elbow motion (and sometimes correlating the shoulder and wrist) leads to solutions that are more aligned with what users prefer.
&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;p&gt;
    &lt;a href=&#34;https://arxiv.org/abs/1808.03891&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Arxiv Link&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;award&#34;&gt;Award&lt;/h3&gt;
&lt;p&gt;
    &lt;a href=&#34;https://roboticsconference.org/2020/program/awards/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt; IROS 2018 Best Student Paper Finalist&lt;/a&gt;
&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
